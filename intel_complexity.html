<!DOCTYPE html>
<html lang="en">

    
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Intelligence complexity is not model complexity, must include training dynamics and data as well.</title>
    <style>

        code {
            background-color: #f4f4f4;
            padding: 2px 4px;
            border-radius: 4px;
            font-family: monospace;
        }

    </style>
</head>
<body>
    <header>
        <h1>Intelligence complexity is not model complexity, must include the solver, and data as well.</h1>
        <p><em>By Francois Chaubard</em></p>
    </header>

    <section>
        <p>
            For decades, computer scientists and mathematicians have tried to classify the complexity of algorithms and models‚Äîoften in ‚Äúbig-O‚Äù notation similar to P, NP, PSPACE, etc. under the assumption that the <b>model itself</b> is the core entity we need to analyze. 
            But when it comes to <em>intelligence</em>, focusing on the model in isolation overlooks critical factors like the training process (the solver), and data distribution. For example, curriculum learning can greatly improve without curriculum. More trainnig steps outperforms less steps. All with the same model class. Using model alone is not useful as even a 2 layer NN can fit ANY function. So why in practice can't it? Because its not possible to find the magical theta that gets you there. So the solver / training dynamics must be taking into consideration for us to have a useful bound on intelligence to start defining intelligence classes. 
            This post proposes a new perspective: an agent‚Äôs <em>intelligence</em> depends on the <em>synergy</em> of three components‚Äîmodel (architecture + capacity), training data (or experience more broadly), and the solver (all the training dynamics like: SGD, MeZO, adam, lr schedule, weight decay, # of iters, etc etc).
        </p>

        <p>
            We might call this integrated measure:
        </p>
        <pre>
O<sub>Intelligence</sub>(model + solver + data)
        </pre>

        <p>
            where each part plays a role analogous to how, in Einstein‚Äôs theory of relativity, <em>matter</em> and <em>space-time</em> cannot be treated as independent. In the same way, the solver, data, and model architecture are tightly interwoven and shape each other.
        </p>
    </section>

    <section>
        <h2>1. The Pitfall of Looking at Models in Isolation</h2>
        <p>
            In the machine learning world, we often talk about model complexity‚Äîlike the number of parameters in a neural network, or the depth/width of layers‚Äîas if <em>that alone</em> determines learning capacity. The classic big-O notation helps us discuss computational or memory costs of <em>running</em> or <em>training</em> the model, but it rarely captures the model‚Äôs actual ability to <em>generalize</em>.
        </p>
        <p>
            <strong>Key takeaway:</strong> Looking at <em>any one</em> of these three (model, data, or solver) without the others is akin to analyzing a planet‚Äôs motion in purely Newtonian terms, ignoring the fact that mass and spacetime curvature are intertwined in Einstein‚Äôs relativity.
        </p>
    </section>

    <section>
        <h2>2. Intelligence as ‚ÄúPerformance Over Tasks‚Äù</h2>
        <h3>2.1 A More General Definition</h3>
        <p>
            One way to define <em>intelligence</em> is in terms of <em>average performance</em> on a <em>broad set</em> of tasks. This echoes ideas from the Legg-Hutter measure of universal intelligence, which looks at how an agent performs across all computable environments. 
        </p>
        <h3>2.2 Why the Holistic View Matters</h3>
        <p>
            If we let <code>&#x1D54C;</code> represent a set of tasks and <code>Perf(agent, &#x1D54C;)</code> represent the agent‚Äôs average performance on these tasks, then a <em>rough</em> measure of intelligence might be:
        </p>
        <pre>
Intelligence(agent) ‚âà ùîº<sub>t‚àà&#x1D54C;</sub>[Perf(agent, t)]
        </pre>
    </section>

    <section>
        <h2>3. The Analogy: Newton vs. Einstein</h2>
        <h3>3.1 Matter and Spacetime</h3>
        <p>
            In Newtonian mechanics, we often see space and time as fixed backgrounds and treat objects (matter) as separate. Einstein‚Äôs theory of general relativity flips that picture: <em>matter-energy</em> warps <em>spacetime</em>, and <em>spacetime curvature</em> affects how matter moves. They are intertwined, not independent.
        </p>
    </section>

    <section>
        <h2>4. From Big-O to ‚ÄúHolistic‚Äù Complexity</h2>
        <h3>4.1 Classical Big-O in Machine Learning</h3>
        <p>
            Classical big-O typically gives you something like:
        </p>
        <ul>
            <li><strong>Training Complexity:</strong> <code>O(N √ó model cost)</code> for <code>N</code> training samples.</li>
            <li><strong>Inference Complexity:</strong> <code>O(d √ó model cost)</code> for <code>d</code> input features.</li>
        </ul>
    </section>

    <section>
        <h2>5. Potential Objections &amp; Discussion</h2>
        <p><strong>1. Isn‚Äôt This Just Legg-Hutter or Universal Intelligence?</strong></p>
        <p>Similar spirit, different emphasis.</p>
        <p><strong>2. Measuring ‚ÄúAll Possible Tasks‚Äù is Impossible</strong></p>
        <p>Indeed, we can‚Äôt measure literally <em>everything</em>.</p>
    </section>

<h3>  Return <a href = "./index.html">Home</a> </h3> 
</body>
</html>
